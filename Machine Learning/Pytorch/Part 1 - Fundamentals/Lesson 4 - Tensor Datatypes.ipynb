{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "\n",
    "**Note:** Tensor datatypes is one of the 3 big issues/errors that will be encountered with Pytorch & deep learning\n",
    "1. Tensors not right datatype: dtype (float16 tensors but computing as if if were in float32, will yield in an error --> this is not always the case)\n",
    "2. Tensors not right shape (Matrix multiplcation)\n",
    "3. Tensors not on the right device: device (\"cpu\", \"cuda\" --> erros occur when one tensor is one a cpu and another is on a gpu, and you attempt multiplcation between the two of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "\n",
    "float32Tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                             dtype = None)\n",
    "\n",
    "# creating a tensor that does not have a dtype to see what the output will be\n",
    "\n",
    "float32Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32Tensor.dtype\n",
    "# even though we specifed the data type as none it still comes out as float32 since that is the default data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16Tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                             dtype = torch.float16,\n",
    "                             device = None,)\n",
    "\n",
    "float16Tensor.dtype\n",
    "# this shows that as long as you give a proper data type then the tensor will be created with that data type, and the default data type will not be used, but if nothing is given then it resorts to the default data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32Tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                             dtype = None, # what is the datatype of the tensor is: eg. torch.float32, \n",
    "                             # datatypes are important in the precision of the data, determines the amount of space that it will take up: faster calculations with less or lower memory\n",
    "                             device = \"cuda\", # is the device tensor is on: eg. cpu, gpu, cuda\n",
    "                             requires_grad = False # want pytorch to track the gradients of the tensor\n",
    "                             )\n",
    "\n",
    "# when creating tensors dtype, device, and requires_grad are the 3 most impotant parameters, but you are not doing something that requires specific values you can ignore this since pytorch will do this\n",
    "# in the background for you\n",
    "\n",
    "float32Tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16Tensor = float32Tensor.to(torch.float16)\n",
    "# if you want the same tensor but in a smaller data type you can use the .to() method to convert to float16\n",
    "\n",
    "float16Tensor\n",
    "# as seen in the output, the two tensors are the same but the data type is now in type float16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
