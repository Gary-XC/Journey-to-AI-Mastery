{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code From Previous Parts in PyTorch Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data points imported from lesson 19\n",
    "\n",
    "weight = 0.91\n",
    "bias = 0.3\n",
    "\n",
    "# Create\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "# parameters for creating the tensor: X\n",
    "\n",
    "X = torch.arange(start, end, step).unsqueeze(dim = 1)\n",
    "# adds an extra dimension so theres an extra square bracket and each element of X, y are on different lines in the output for betting viewing\n",
    "y = weight * X + bias # is Linear Regression Formula\n",
    "\n",
    "\n",
    "trainSplit = int(0.8 * len(X)) # creating the train split by multiplying the upper bounds of the train split by the length of X to get the total number\n",
    "\n",
    "XTrain, yTrain = X[:trainSplit], y[:trainSplit] # indexing to get all samples up until the trainsplit\n",
    "XTest, yTest = X[trainSplit:], y[trainSplit:] # indexing to get all the samples from the trainsplit onwards, or what is left over after the trainsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model imported from lesson 20\n",
    "\n",
    "class LinearRegressionModel(nn.Module): # almost everything in Pytorch inherits from nn.Module, and can be considered the building blocks for pytorch\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.randn(1,\n",
    "                                                requires_grad=True, # grad = True is set by default, one of the main algorithms for predictions\n",
    "                                                dtype= torch.float))\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.randn(1,\n",
    "                                             requires_grad= True,\n",
    "                                             dtype= torch.float))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # -> means the return value, very similar to java, but for python its included outside of the method\n",
    "        # 'x' is the input data\n",
    "        return self.weights * x + self.bias # linear regression formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code imported from lesson 22\n",
    "# creating a random seed\n",
    "torch.manual_seed(246)\n",
    "\n",
    "# creating an instance of the model which is a subclass of nn.Module\n",
    "model0 = LinearRegressionModel() # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code imported from lesson 25\n",
    "\n",
    "lossFunction = nn.L1Loss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model0.parameters(),\n",
    "                            lr= 0.01, # learning rate - is the most important hyperparameter that the programmer can set, the smaller the learning rate, the smaller the change\n",
    "                                      # in the parameters, and the larger the learning rate, the larger the change of the parameters\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "torch.manual_seed(246)\n",
    "\n",
    "# an epoch is a loop through the data, and is a hyperparameter since we set it ourselves \n",
    "epochs = 10\n",
    "\n",
    "# 1. Loop through the data (have to execute all the training loop steps in the for loop below\n",
    "for epoch in range(epochs):\n",
    "    # setting the model to training mode, which is the calling the function .train() on the model, in Pytorch train mode sets all parameters that need parameters to require parameters\n",
    "    model0.train() # default mode/state of the model\n",
    "\n",
    "    # 2. Forward Pass\n",
    "    yPred = model0(XTrain) # learning patterns on the training data, and evaluating data on the test data, and uses the Forward method\n",
    "\n",
    "    # 3. Calculating the Loss (Mean Absolute Error or MAE) or the distance from the test values(green dots), and the values that the model gave(red dots)\n",
    "    loss = lossFunction(yPred, yTrain) # lossFunction = nn.L1Loss()\n",
    "\n",
    "    # 4. Optimizer zero grad \n",
    "    optimizer.zero_grad() # optimizer = torch.optim.SGD(params=model0.parameters(),lr= 0.01,)\n",
    "\n",
    "    # 5. Backpropagation with respect to the loss with the models parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # 6. Optimizer step (perform the gradient descent), makes calculations in how the model should adjust the parameters based on the loss of the back propagation \n",
    "    optimizer.step() \n",
    "    # by default, the change of the optimizer will accumulate through the loop, so step 4 is important to prevent the model from cycling different epochs, and .zero_grad will reset the epoch\n",
    "\n",
    "    model0.eval() # turns off gradient tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Training Loop: Epoch By Epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
